{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モジュールをインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_prob = 0.5\n",
    "n_labels = 5\n",
    "training_epochs = 10\n",
    "batch_size = 300\n",
    "learning_rate = 1e-4\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Input, LSTM, Conv2D, Conv3D\n",
    "from tensorflow.keras.layers import Reshape, Flatten, Softmax\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def model(input_shape):\n",
    "    \"\"\"\n",
    "    Function creating the model's graph in Keras.\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    X_input = Input(shape = input_shape)\n",
    "\n",
    "    conv_1 = Conv3D(filters=32, kernel_size=(3, 3, 3), padding=\"same\", strides=(1, 1, 1), activation=\"elu\")(X_input)\n",
    "    conv_2 = Conv3D(filters=64, kernel_size=(3, 3, 3), padding=\"same\", strides=(1, 1, 1), activation=\"elu\")(conv_1)\n",
    "    conv_3 = Conv3D(filters=128, kernel_size=(3, 3, 3), padding=\"same\", strides=(1, 1, 1), activation=\"elu\")(conv_2)\n",
    "    shape = conv_3.get_shape().as_list()\n",
    "    \n",
    "    pool_2_flat = Reshape([shape[1], shape[2]*shape[3]*shape[4]])(conv_3)\n",
    "    fc = Dense(1024, activation=\"elu\")(pool_2_flat)\n",
    "    fc_drop = Dropout(dropout_prob)(fc)\n",
    "    \n",
    "    lstm_in = Reshape([10, 1024])(fc_drop)\n",
    "    lstm_1 = LSTM(units=1024, return_sequences=True, unit_forget_bias=True, dropout=dropout_prob)(lstm_in)\n",
    "    rnn_output = LSTM(units=1024, return_sequences=False, unit_forget_bias=True)(lstm_1)\n",
    "    \n",
    "    shape_rnn_out = rnn_output.get_shape().as_list()\n",
    "    fc_out = Dense(shape_rnn_out[1], activation=\"elu\")(rnn_output)\n",
    "    fc_drop = Dropout(dropout_prob)(fc_out)\n",
    "    y_ = Dense(n_labels)(fc_drop)\n",
    "    y_posi = Softmax()(y_)\n",
    "#     X = Argmax()(X)\n",
    "#     X = argmax()(X)\n",
    "#     X = Dense(5, activation=\"elu\")(X)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = y_posi)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\n"
    }
   ],
   "source": [
    "model = model(input_shape = (10, 10, 11, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 10, 10, 11, 1)]   0         \n_________________________________________________________________\nconv3d (Conv3D)              (None, 10, 10, 11, 32)    896       \n_________________________________________________________________\nconv3d_1 (Conv3D)            (None, 10, 10, 11, 64)    55360     \n_________________________________________________________________\nconv3d_2 (Conv3D)            (None, 10, 10, 11, 128)   221312    \n_________________________________________________________________\nreshape (Reshape)            (None, 10, 14080)         0         \n_________________________________________________________________\ndense (Dense)                (None, 10, 1024)          14418944  \n_________________________________________________________________\ndropout (Dropout)            (None, 10, 1024)          0         \n_________________________________________________________________\nreshape_1 (Reshape)          (None, 10, 1024)          0         \n_________________________________________________________________\nlstm (LSTM)                  (None, 10, 1024)          8392704   \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 1024)              8392704   \n_________________________________________________________________\ndense_1 (Dense)              (None, 1024)              1049600   \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 1024)              0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 5)                 5125      \n_________________________________________________________________\nsoftmax (Softmax)            (None, 5)                 0         \n=================================================================\nTotal params: 32,536,645\nTrainable params: 32,536,645\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=learning_rate)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みモデルの重みを読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f8cd2e22a20>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"./results/keras_2019_11_21/keras_model/cp.ckpt\"\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylsl import StreamInlet, resolve_byprop\n",
    "from muselsl.constants import LSL_SCAN_TIMEOUT, LSL_EEG_CHUNK\n",
    "\n",
    "LSL_EEG_CHUNK = 10\n",
    "def record_stream():\n",
    "    \"\"\"\n",
    "    :return: a generator to fetch EEG data from existed stream.\n",
    "    \"\"\"\n",
    "    streams = resolve_byprop(\"type\", \"EEG\", timeout=LSL_SCAN_TIMEOUT)\n",
    "    if len(streams) == 0:\n",
    "        raise IOError(\"Can't find EEG stream.\")\n",
    "\n",
    "    inlet = StreamInlet(streams[0], max_buflen=LSL_EEG_CHUNK)\n",
    "\n",
    "    info = inlet.info()\n",
    "    description = info.desc()\n",
    "    Nchan = info.channel_count()\n",
    "\n",
    "    ch = description.child('channels').first_child()\n",
    "    ch_names = [ch.child_value(\"label\")]\n",
    "    for i in range(1, Nchan):\n",
    "        ch = ch.next_sibling()\n",
    "        ch_names.append(ch.child_value('label'))\n",
    "#     print(ch_names)\n",
    "    while True:\n",
    "        yield inlet.pull_chunk(timeout=1.0, max_samples=LSL_EEG_CHUNK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['TP9', 'AF7', 'AF8', 'TP10', 'Right AUX']\n[[  914.0625     -1000.          -890.13671875  -516.6015625 ]\n [ -489.74609375   136.71875     -424.8046875    971.19140625]\n [-1000.          -711.42578125  -146.97265625  -985.3515625 ]\n [ -262.20703125   474.12109375  -250.           -54.6875    ]\n [ -865.72265625 -1000.          -718.75        -932.6171875 ]\n [  119.62890625  -246.58203125  -565.4296875    425.78125   ]\n [-1000.          -862.79296875   -53.22265625  -830.078125  ]\n [ -811.5234375    994.62890625   -49.8046875    211.9140625 ]\n [  770.99609375  -543.9453125   -481.93359375 -1000.        ]\n [  329.58984375  -407.71484375  -681.15234375  -140.13671875]]\n"
    }
   ],
   "source": [
    "print(\"['TP9', 'AF7', 'AF8', 'TP10', 'Right AUX']\")\n",
    "print(np.array(next(record_stream())[0])[:, 0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_1Dto2D(data, Y=10, X=11):\n",
    "    data_2D = np.zeros([Y, X])\n",
    "    data_2D[1, 3] = data[1]\n",
    "    data_2D[1, 7] = data[2]\n",
    "    data_2D[5, 1] = data[0]\n",
    "    data_2D[5, 9] = data[3]\n",
    "# \tdata_2D[0] = ( \t   \t 0, \t   0,  \t   \t 0, \t   0,        0,        0,        0, \t   0,  \t     0, \t   0, \t \t 0) \n",
    "# \tdata_2D[1] = (\t  \t 0, \t   0,  \t   \t 0, data[1],        0,        0,        0, data[2], \t   \t 0,   \t   0, \t \t 0) \n",
    "# \tdata_2D[2] = (\t  \t 0,        0,        0,        0,        0,        0,        0,        0,        0,        0, \t \t 0) \n",
    "# \tdata_2D[3] = (\t  \t 0,        0,        0,        0,        0,        0,        0,        0,        0,        0, \t\t 0) \n",
    "# \tdata_2D[4] = (       0,        0,        0,        0,        0,        0,        0,        0,        0,        0,        0) \n",
    "# \tdata_2D[5] = (\t  \t 0, data[0],        0,        0,        0,        0,        0,        0,        0, data[3], \t\t 0) \n",
    "# \tdata_2D[6] = (\t  \t 0,        0,        0,        0,        0,        0,        0,        0,        0,        0, \t\t 0) \n",
    "# \tdata_2D[7] = (\t  \t 0, \t   0, \t \t 0,        0,        0,        0,        0,        0, \t   \t 0, \t   0, \t\t 0) \n",
    "# \tdata_2D[8] = (\t  \t 0, \t   0, \t \t 0, \t   0,        0,        0,        0, \t   0, \t   \t 0, \t   0, \t\t 0) \n",
    "# \tdata_2D[9] = (\t  \t 0, \t   0, \t \t 0, \t   0, \t     0,        0, \t\t 0, \t   0, \t   \t 0, \t   0, \t\t 0) \n",
    "    return data_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_2d = np.zeros((10, 10, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = buffer_2d.reshape((1, 10, 10, 11, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "image_open&close_both_fists\neye_close\neye_close\neye_close\neye_close\neye_close\neye_close\neye_close\neye_close\neye_close\neye_close\nimage_open&close_both_fists\n"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-584b51a558ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mbuffer_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     print(stream[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mbuffer_2d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-2485984e7758>\u001b[0m in \u001b[0;36mrecord_stream\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0mto\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0mEEG\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexisted\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \"\"\"\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mstreams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresolve_byprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"EEG\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLSL_SCAN_TIMEOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreams\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't find EEG stream.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pylsl/pylsl.py\u001b[0m in \u001b[0;36mresolve_byprop\u001b[0;34m(prop, value, minimum, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m                                        \u001b[0mc_char_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                                        \u001b[0mminimum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                                        c_double(timeout))\n\u001b[0m\u001b[1;32m    550\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mStreamInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "true_labels = ['eye_close', 'image_open&close_both_feet',\n",
    "       'image_open&close_both_fists', 'image_open&close_left_fist',\n",
    "       'image_open&close_right_fist']\n",
    "for stream in record_stream():\n",
    "    buffer_2d = np.zeros((10, 10, 11))\n",
    "#     print(stream[0])\n",
    "    for i in next(record_stream())[0]:\n",
    "        num = 0\n",
    "        buffer_2d[num, 1, 3] = i[1]\n",
    "        buffer_2d[num, 1, 7] = i[2]\n",
    "        buffer_2d[num, 5, 1] = i[0]\n",
    "        buffer_2d[num, 5, 9] = i[3]\n",
    "    X_test = buffer_2d.reshape((1, 10, 10, 11, 1))\n",
    "    y_pred = model.predict(X_test, batch_size=1, verbose=0)\n",
    "    y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    print(true_labels[int(y_pred_bool)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テストデータを分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, batch_size=1, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"サンプリング率:\", 160)\n",
    "print(\"1秒に処理できる信号数：\", 990*10-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bool = one_hot_encoder(y_pred_bool)\n",
    "y_pred_bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 精度と正解率の曲線"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "for i in range(5):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i],\n",
    "                                                        y_pred_bool[:, i])\n",
    "    plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n",
    "\n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"precision\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"precision vs. recall curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"検証正解率：\", history[\"val_acc\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"テスト正解率：\", accuracy_score(y_test, y_pred_bool))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}