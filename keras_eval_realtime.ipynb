{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モジュールをインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"./results/keras_2020_01_27_14_45\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = load_model(results_dir + \"/model/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10, 1, 4, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 10, 1, 4, 128)     384       \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 10, 512)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10, 256)           131328    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 10, 512)           787968    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 10, 512)           1181184   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 512)               1181184   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 2565      \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 3,547,269\n",
      "Trainable params: 3,547,269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = Adam(lr=learning_rate)\n",
    "# model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みモデルの重みを読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = \"./results/keras_2019_11_21/keras_model/cp.ckpt\"\n",
    "# model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pylsl import StreamInlet, resolve_byprop, local_clock\n",
    "# from muselsl.constants import LSL_SCAN_TIMEOUT, LSL_EEG_CHUNK\n",
    "# from datetime import datetime\n",
    "# LSL_EEG_CHUNK = 10\n",
    "# def record_stream():\n",
    "#     \"\"\"\n",
    "#     :return: a generator to fetch EEG data from existed stream.\n",
    "#     \"\"\"\n",
    "#     streams = resolve_byprop(\"type\", \"EEG\", timeout=LSL_SCAN_TIMEOUT)\n",
    "#     if len(streams) == 0:\n",
    "#         raise IOError(\"Can't find EEG stream.\")\n",
    "\n",
    "#     inlet = StreamInlet(streams[0], max_buflen=LSL_EEG_CHUNK)\n",
    "\n",
    "#     while True:\n",
    "#         chunk, timestamp = inlet.pull_sample(timeout=1.0)\n",
    "#         if timestamp:\n",
    "#             timestamp = datetime.fromtimestamp(timestamp).strftime(\"%A, %B %d, %Y %I:%M:%S\")\n",
    "#             print(timestamp, end=\"\\r\", flush=True)\n",
    "# record_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylsl import StreamInlet, resolve_byprop\n",
    "from muselsl.constants import LSL_SCAN_TIMEOUT, LSL_EEG_CHUNK\n",
    "\n",
    "LSL_EEG_CHUNK = 20\n",
    "def record_stream():\n",
    "    \"\"\"\n",
    "    :return: a generator to fetch EEG data from existed stream.\n",
    "    \"\"\"\n",
    "    streams = resolve_byprop(\"type\", \"EEG\", timeout=LSL_SCAN_TIMEOUT)\n",
    "    if len(streams) == 0:\n",
    "        raise IOError(\"Can't find EEG stream.\")\n",
    "\n",
    "    inlet = StreamInlet(streams[0], max_buflen=LSL_EEG_CHUNK)\n",
    "\n",
    "    while True:\n",
    "        yield inlet.pull_chunk(timeout=1.0, max_samples=LSL_EEG_CHUNK)\n",
    "#         return inlet.pull_chunk(timeout=1.0, max_samples=LSL_EEG_CHUNK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  -36.62109375   -47.36328125    54.6875       -46.38671875\n",
      "    732.91015625]\n",
      " [  -63.4765625    -75.68359375    61.5234375    -77.63671875\n",
      "   -616.69921875]\n",
      " [  -62.98828125   -80.078125      58.59375      -79.58984375\n",
      "   -907.2265625 ]\n",
      " [  -39.55078125   -57.6171875     54.19921875   -56.640625\n",
      "    116.2109375 ]\n",
      " [  -25.390625     -47.8515625     54.19921875   -41.9921875\n",
      "    964.35546875]\n",
      " [  -56.15234375   -74.21875       59.08203125   -67.87109375\n",
      "   -210.44921875]\n",
      " [  -68.84765625   -77.1484375     58.59375      -84.47265625\n",
      "   -987.79296875]\n",
      " [  -53.7109375    -63.4765625     52.24609375   -74.70703125\n",
      "   -231.4453125 ]\n",
      " [  -32.71484375   -41.9921875     44.921875     -46.875\n",
      "    908.69140625]\n",
      " [  -53.22265625   -70.3125        50.29296875   -64.94140625\n",
      "    167.48046875]\n",
      " [  -72.265625     -87.890625      56.640625     -90.8203125\n",
      "  -1000.        ]\n",
      " [  -61.5234375    -66.40625       56.640625     -78.125\n",
      "   -595.21484375]\n",
      " [  -36.1328125    -46.875         52.24609375   -54.6875\n",
      "    593.26171875]\n",
      " [  -44.43359375   -59.5703125     52.24609375   -62.98828125\n",
      "    479.00390625]\n",
      " [  -75.68359375   -90.33203125    58.10546875   -93.75\n",
      "   -873.53515625]\n",
      " [  -67.3828125    -79.58984375    50.78125      -87.40234375\n",
      "   -770.5078125 ]\n",
      " [  -41.50390625   -56.15234375    39.55078125   -62.01171875\n",
      "    331.54296875]\n",
      " [  -39.55078125   -58.10546875    44.43359375   -57.12890625\n",
      "    792.96875   ]\n",
      " [  -70.3125       -81.54296875    56.15234375   -83.49609375\n",
      "   -534.1796875 ]\n",
      " [  -67.87109375   -82.51953125    59.08203125   -84.9609375\n",
      "   -985.83984375]]\n"
     ]
    }
   ],
   "source": [
    "samples, timestamps = next(record_stream())\n",
    "# print(samples)\n",
    "samples = np.array(samples)\n",
    "print(samples)\n",
    "# for sample in samples:\n",
    "#     print(sample[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1580196165.288805\n",
      "1580196165.2927113\n",
      "1580196165.2966175\n",
      "1580196165.3005238\n",
      "1580196165.30443\n",
      "1580196165.3083363\n",
      "1580196165.3122425\n",
      "1580196165.3161488\n",
      "1580196165.320055\n",
      "1580196165.3239613\n",
      "1580196165.3278675\n",
      "1580196165.3317738\n",
      "1580196165.33568\n",
      "1580196165.3395863\n",
      "1580196165.3434925\n",
      "1580196165.3473988\n",
      "1580196165.351305\n",
      "1580196165.3552113\n",
      "1580196165.3591175\n",
      "1580196165.3630238\n"
     ]
    }
   ],
   "source": [
    "for timestamp in timestamps:\n",
    "    print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"['TP9', 'AF7', 'AF8', 'TP10', 'Right AUX']\")\n",
    "# print(np.array(next(record_stream())[0])[:, 0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_dir + \"/ohe\", \"rb\") as file:\n",
    "    ohe = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eye_close' 'image_open&close_both_feet' 'image_open&close_both_fists'\n",
      " 'image_open&close_left_fist' 'image_open&close_right_fist']\n"
     ]
    }
   ],
   "source": [
    "true_labels = ohe.categories_[0]\n",
    "print(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_dir + \"/scaler\", \"rb\") as file:\n",
    "    scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -0.3579738 , -18.1131563 , -16.02667461,  -1.57742181])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 59.46182455, 107.01945638, 104.94636896,  62.93448588])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_normalize(data):\n",
    "\tmean = data[data.nonzero()].mean()\n",
    "\tsigma = data[data.nonzero()].std()\n",
    "\tdata_normalized = data\n",
    "\tdata_normalized[data_normalized.nonzero()] = (data_normalized[data_normalized.nonzero()] - mean)/sigma\n",
    "\treturn data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eye_close' 'image_open&close_both_feet' 'image_open&close_both_fists'\n",
      " 'image_open&close_left_fist' 'image_open&close_right_fist']\n",
      "16:24:26:812243  [[False False False False False]]\r"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "# print(\"23:51:39:746923  [[False False  True False False]]\")\n",
    "print(true_labels)\n",
    "# print(\"Timestamp          Results\")\n",
    "for stream, timestamps in record_stream():\n",
    "    stream = np.array(stream)\n",
    "    stream = stream[::2]\n",
    "    stream = stream[:, :4]\n",
    "#     stream = (stream - scaler.mean_) / scaler.scale_\n",
    "    timestamps = timestamps[::2]\n",
    "    buffer_3d = []\n",
    "    buffer_2d = np.zeros((1, 4))\n",
    "    for data in stream:\n",
    "        data = feature_normalize(data)\n",
    "        \n",
    "#         buffer_2d[1, 3] = data[1]\n",
    "#         buffer_2d[1, 7] = data[2]\n",
    "#         buffer_2d[5, 1] = data[0]\n",
    "#         buffer_2d[5, 9] = data[3]\n",
    "        buffer_2d[0, 0] = data[1]\n",
    "        buffer_2d[0, 1] = data[2]\n",
    "        buffer_2d[0, 2] = data[0]\n",
    "        buffer_2d[0, 3] = data[3]\n",
    "        buffer_3d.append(buffer_2d)\n",
    "    buffer_3d = np.array(buffer_3d)\n",
    "    X_test = buffer_3d.reshape((1, 10, 1, 4, 1))\n",
    "    y_pred = model.predict(X_test, batch_size=1, verbose=0)\n",
    "    y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "#     print(y_pred.round(3), end=\"\\r\", flush=True)\n",
    "#     print(y_pred.shape)\n",
    "    y_pred_confidence = (y_pred > 0.6)\n",
    "#     print(y_pred_confidence.shape)\n",
    "    y_pred_confidence_bool = np.argmax(y_pred_confidence, axis=1)\n",
    "#     print(y_pred_confidence)\n",
    "#     print(y_pred_confidence_bool)\n",
    "#     if True in pred_confidence:\n",
    "        \n",
    "#     print(y_pred.round(3), end=\"\\r\", flush=True)\n",
    "#     print(datetime.fromtimestamp(timestamps[-1]).strftime(\"%H:%M:%S:%f\")\n",
    "#           + \"  \" + str(y_pred), end=\"\\r\", flush=True)\n",
    "#     print(datetime.fromtimestamp(timestamps[-1]).strftime(\"%H:%M:%S:%f\")\n",
    "#           + \"  \" + str(true_labels[int(y_pred_bool)]), end=\"\\r\", flush=True)\n",
    "    print(datetime.fromtimestamp(timestamps[-1]).strftime(\"%H:%M:%S:%f\")\n",
    "          + \"  \" + str(y_pred_confidence), end=\"\\r\", flush=True)\n",
    "#     print(y_pred.reshape(-1).shape)    \n",
    "#     print(y_pred, end=\"\\n\")\n",
    "#     print(flush=True)\n",
    "#     y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "#     print(true_labels[int(y_pred_bool)], end=\"\\r\", flush=True)\n",
    "#     print(true_labels[int(y_pred_bool)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
