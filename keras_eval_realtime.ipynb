{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モジュールをインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"./results/keras_2019_12_23_12_11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = load_model(results_dir + \"/model/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10, 10, 11, 1)]   0         \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 10, 10, 11, 128)   1280      \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 10, 14080)         0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10, 1024)          14418944  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 1024)          0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 10, 1024)          0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 1024)              6294528   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 5125      \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 21,769,477\n",
      "Trainable params: 21,769,477\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = Adam(lr=learning_rate)\n",
    "# model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みモデルの重みを読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = \"./results/keras_2019_11_21/keras_model/cp.ckpt\"\n",
    "# model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pylsl import StreamInlet, resolve_byprop, local_clock\n",
    "# from muselsl.constants import LSL_SCAN_TIMEOUT, LSL_EEG_CHUNK\n",
    "# from datetime import datetime\n",
    "# LSL_EEG_CHUNK = 10\n",
    "# def record_stream():\n",
    "#     \"\"\"\n",
    "#     :return: a generator to fetch EEG data from existed stream.\n",
    "#     \"\"\"\n",
    "#     streams = resolve_byprop(\"type\", \"EEG\", timeout=LSL_SCAN_TIMEOUT)\n",
    "#     if len(streams) == 0:\n",
    "#         raise IOError(\"Can't find EEG stream.\")\n",
    "\n",
    "#     inlet = StreamInlet(streams[0], max_buflen=LSL_EEG_CHUNK)\n",
    "\n",
    "#     while True:\n",
    "#         chunk, timestamp = inlet.pull_sample(timeout=1.0)\n",
    "#         if timestamp:\n",
    "#             timestamp = datetime.fromtimestamp(timestamp).strftime(\"%A, %B %d, %Y %I:%M:%S\")\n",
    "#             print(timestamp, end=\"\\r\", flush=True)\n",
    "# record_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylsl import StreamInlet, resolve_byprop\n",
    "from muselsl.constants import LSL_SCAN_TIMEOUT, LSL_EEG_CHUNK\n",
    "\n",
    "LSL_EEG_CHUNK = 10\n",
    "def record_stream():\n",
    "    \"\"\"\n",
    "    :return: a generator to fetch EEG data from existed stream.\n",
    "    \"\"\"\n",
    "    streams = resolve_byprop(\"type\", \"EEG\", timeout=LSL_SCAN_TIMEOUT)\n",
    "    if len(streams) == 0:\n",
    "        raise IOError(\"Can't find EEG stream.\")\n",
    "\n",
    "    inlet = StreamInlet(streams[0], max_buflen=LSL_EEG_CHUNK)\n",
    "\n",
    "    while True:\n",
    "        yield inlet.pull_chunk(timeout=1.0, max_samples=LSL_EEG_CHUNK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[353.515625, 28.80859375, 30.2734375, 855.95703125, 61.03515625], [94.7265625, 34.66796875, 41.50390625, 347.65625, 81.54296875], [-274.4140625, 39.55078125, 40.52734375, -700.68359375, -20.5078125], [-119.140625, 36.62109375, 30.76171875, -474.609375, -32.2265625], [312.01171875, 30.2734375, 28.80859375, 655.76171875, 45.41015625], [229.4921875, 35.64453125, 37.109375, 615.234375, 55.17578125], [-208.49609375, 43.45703125, 43.45703125, -521.97265625, 17.578125], [-213.8671875, 38.57421875, 35.64453125, -667.96875, 13.18359375], [196.2890625, 27.83203125, 25.87890625, 364.74609375, 46.38671875], [318.359375, 29.78515625, 34.66796875, 830.078125, 93.26171875]]\n"
     ]
    }
   ],
   "source": [
    "samples, timestamps = next(record_stream())\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1577257225.0890708, 1577257225.092977, 1577257225.0968833, 1577257225.1007895, 1577257225.1046958, 1577257225.108602, 1577257225.1125083, 1577257225.1164145, 1577257225.1203208, 1577257225.124227]\n"
     ]
    }
   ],
   "source": [
    "print(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"['TP9', 'AF7', 'AF8', 'TP10', 'Right AUX']\")\n",
    "# print(np.array(next(record_stream())[0])[:, 0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_1Dto2D(data, Y=10, X=11):\n",
    "    data_2D = np.zeros([Y, X])\n",
    "    data_2D[1, 3] = data[1]\n",
    "    data_2D[1, 7] = data[2]\n",
    "    data_2D[5, 1] = data[0]\n",
    "    data_2D[5, 9] = data[3]\n",
    "# \tdata_2D[0] = ( \t   \t 0, \t   0,  \t   \t 0, \t   0,        0,        0,        0, \t   0,  \t     0, \t   0, \t \t 0) \n",
    "# \tdata_2D[1] = (\t  \t 0, \t   0,  \t   \t 0, data[1],        0,        0,        0, data[2], \t   \t 0,   \t   0, \t \t 0) \n",
    "# \tdata_2D[2] = (\t  \t 0,        0,        0,        0,        0,        0,        0,        0,        0,        0, \t \t 0) \n",
    "# \tdata_2D[3] = (\t  \t 0,        0,        0,        0,        0,        0,        0,        0,        0,        0, \t\t 0) \n",
    "# \tdata_2D[4] = (       0,        0,        0,        0,        0,        0,        0,        0,        0,        0,        0) \n",
    "# \tdata_2D[5] = (\t  \t 0, data[0],        0,        0,        0,        0,        0,        0,        0, data[3], \t\t 0) \n",
    "# \tdata_2D[6] = (\t  \t 0,        0,        0,        0,        0,        0,        0,        0,        0,        0, \t\t 0) \n",
    "# \tdata_2D[7] = (\t  \t 0, \t   0, \t \t 0,        0,        0,        0,        0,        0, \t   \t 0, \t   0, \t\t 0) \n",
    "# \tdata_2D[8] = (\t  \t 0, \t   0, \t \t 0, \t   0,        0,        0,        0, \t   0, \t   \t 0, \t   0, \t\t 0) \n",
    "# \tdata_2D[9] = (\t  \t 0, \t   0, \t \t 0, \t   0, \t     0,        0, \t\t 0, \t   0, \t   \t 0, \t   0, \t\t 0) \n",
    "    return data_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = np.array(['eye_close', 'image_open&close_both_feet',\n",
    "       'image_open&close_both_fists', 'image_open&close_left_fist',\n",
    "       'image_open&close_right_fist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_normalize(data):\n",
    "\tmean = data[data.nonzero()].mean()\n",
    "\tsigma = data[data.nonzero()].std()\n",
    "\tdata_normalized = data\n",
    "\tdata_normalized[data_normalized.nonzero()] = (data_normalized[data_normalized.nonzero()] - mean)/sigma\n",
    "\treturn data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp          Results\n",
      "16:01:12:592977  eye_closen&close_right_fist\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f4777edfa19e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mbuffer_2d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mbuffer_2d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-25fdcd0d5bfa>\u001b[0m in \u001b[0;36mfeature_normalize\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdata_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mdata_normalized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_normalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_normalized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_normalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata_normalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "# print(\"23:51:39:746923  [[False False  True False False]]\")\n",
    "# print(\"   Timestamp##################Results#############\")\n",
    "print(\"Timestamp          Results\")\n",
    "\n",
    "for stream, timestamps in record_stream():\n",
    "    buffer_3d = []\n",
    "    buffer_2d = np.zeros((10, 11))\n",
    "    num = 0\n",
    "    for data in stream:\n",
    "        data = np.array(data)\n",
    "        data = feature_normalize(data)\n",
    "        buffer_2d[1, 3] = data[1]\n",
    "        buffer_2d[1, 7] = data[2]\n",
    "        buffer_2d[5, 1] = data[0]\n",
    "        buffer_2d[5, 9] = data[3]\n",
    "        buffer_3d.append(buffer_2d)\n",
    "    buffer_3d = np.array(buffer_3d)\n",
    "    X_test = buffer_3d.reshape((1, 10, 10, 11, 1))\n",
    "    y_pred = model.predict(X_test, batch_size=1, verbose=0)\n",
    "    y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "#     print(y_pred.round(3), end=\"\\r\", flush=True)\n",
    "#     y_pred = (y_pred > 0.8)\n",
    "#     print(datetime.fromtimestamp(timestamps[-1]).strftime(\"%H:%M:%S:%f\")\n",
    "#           + \"  \" + str(y_pred), end=\"\\r\", flush=True)\n",
    "    print(datetime.fromtimestamp(timestamps[-1]).strftime(\"%H:%M:%S:%f\")\n",
    "          + \"  \" + str(true_labels[int(y_pred_bool)]), end=\"\\r\", flush=True)\n",
    "#     print(y_pred, end=\"\\n\")\n",
    "#     print(flush=True)\n",
    "#     y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "#     print(true_labels[int(y_pred_bool)], end=\"\\r\", flush=True)\n",
    "#     print(true_labels[int(y_pred_bool)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
