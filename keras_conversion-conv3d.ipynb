{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import sklearn\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "random_state = 33\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in: ./results/keras_2019_12_12_20_07\n",
      "\n",
      "Directory ./results/keras_2019_12_12_20_07 already exists. Creating new directory under ./results/keras_2019_12_12_20_07(2)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "now = now.strftime(\"%Y_%m_%d_%H_%M\")\n",
    "\n",
    "results_path = \"./results/keras_\" + now\n",
    "print(\"Saving results in:\", results_path)\n",
    "\n",
    "print()\n",
    "import os\n",
    "try:\n",
    "    os.mkdir(results_path)\n",
    "except OSError:\n",
    "    print(\"Directory %s already exists. Creating new directory under %s(2)\" % (results_path, results_path))\n",
    "    os.mkdir(results_path+ \"(2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_path + \"/readme.txt\", \"w\") as file:\n",
    "    file.write(\"Training data: 1-81 64 channels, Validation data: 82-108 4 channels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data 64 channel 1-81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (474018, 10, 10, 11, 1)\n",
      "Labels shape: (474018,)\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"./dataset/preprocessed_dataset/\"\n",
    "\n",
    "with open(dataset_dir+\"1_81_shuffle_dataset_3D_win_10.pkl\", \"rb\") as fp:\n",
    "    X_train = pickle.load(fp)\n",
    "with open(dataset_dir+\"1_81_shuffle_labels_3D_win_10.pkl\", \"rb\") as fp:\n",
    "    y_train = pickle.load(fp)\n",
    "X_train = X_train.reshape(-1, 10, 10, 11, 1)\n",
    "print(\"Dataset shape:\", X_train.shape)\n",
    "print(\"Labels shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.          0.         -1.76756835 -0.38667332\n",
      "  -0.53203069  0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.         -0.9681028  -0.56837003  0.84886434\n",
      "   0.55814959 -0.9681028   0.          0.          0.        ]\n",
      " [ 0.          0.04939879  1.39395448 -0.78640609  1.93904462  1.61199053\n",
      "   1.17591842  1.28493645 -1.00444215 -0.27765529  0.        ]\n",
      " [ 0.         -0.05961923  0.95788236  1.39395448  1.64832988  1.90270528\n",
      "   1.32127579  0.70350696 -0.09595858 -1.51319295  0.        ]\n",
      " [-0.82274543 -0.89542412  0.44913156  0.81252499  0.66716762  0.77618565\n",
      "   0.15841682  0.19475617 -0.16863726 -1.2224782  -0.89542412]\n",
      " [ 0.         -1.25881755 -0.13229792  0.23109551 -0.02327989  0.30377419\n",
      "   0.23109551  0.23109551  0.37645288 -1.11346017  0.        ]\n",
      " [ 0.         -0.93176346 -0.02327989  0.12207748  0.08573814  0.37645288\n",
      "   0.59448894  0.44913156  0.08573814 -0.24131595  0.        ]\n",
      " [ 0.          0.          0.         -0.35033398 -0.20497661  0.26743485\n",
      "   0.26743485 -0.20497661  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.         -1.04078149 -0.20497661\n",
      "  -0.56837003  0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.         -4.23864365\n",
      "   0.          0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0, 2].reshape(10, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_train = ohe.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation data 4-channel 82-108 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (150241, 10, 10, 11, 1)\n",
      "Labels shape: (150241,)\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"./dataset/preprocessed_dataset/\"\n",
    "result_dir = \"./results/\"\n",
    "\n",
    "with open(dataset_dir+\"82_108_shuffle_dataset_3D_win_10.pkl\", \"rb\") as fp:\n",
    "    X_valid = pickle.load(fp)\n",
    "with open(dataset_dir+\"82_108_shuffle_labels_3D_win_10.pkl\", \"rb\") as fp:\n",
    "    y_valid = pickle.load(fp)\n",
    "X_valid = X_valid.reshape(-1, 10, 10, 11, 1)\n",
    "print(\"Dataset shape:\", X_valid.shape)\n",
    "print(\"Labels shape:\", y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.         -1.89962866  0.          0.\n",
      "   0.          0.26479672  0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.31084833  0.          0.          0.          0.\n",
      "   0.          0.          0.          0.21874512  0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_valid[0, 2].reshape(10, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = y_valid.reshape(-1, 1)\n",
    "y_valid = ohe.transform(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_path + \"/ohe\", \"wb\") as file:\n",
    "    pickle.dump(ohe, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.25, random_state=random_state)\n",
    "# print(\"Train dataset shape:\", X_train.shape)\n",
    "# print(\"Train label shape:\", y_train.shape)\n",
    "# print(\"Test dataset shape:\", X_test.shape)\n",
    "# print(\"Test label shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_prob = 0.5\n",
    "n_labels = y_train.shape[1]\n",
    "training_epochs = 10\n",
    "batch_size = 300\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Input, LSTM, Conv2D, Conv3D\n",
    "from tensorflow.keras.layers import Reshape, Flatten, Softmax\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input_shape):\n",
    "    \"\"\"\n",
    "    Function creating the model's graph in Keras.\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    conv_1 = Conv3D(filters=32, kernel_size=(1, 1, 1), padding=\"same\", strides=(1, 1, 1), activation=\"elu\")(X_input)\n",
    "    conv_2 = Conv3D(filters=64, kernel_size=(1, 1, 1), padding=\"same\", strides=(1, 1, 1), activation=\"elu\")(conv_1)\n",
    "    conv_3 = Conv3D(filters=128, kernel_size=(1, 1, 1), padding=\"same\", strides=(1, 1, 1), activation=\"elu\")(conv_2)\n",
    "    shape = conv_3.get_shape().as_list()\n",
    "    \n",
    "    pool_2_flat = Reshape([shape[1], shape[2]*shape[3]*shape[4]])(conv_3)\n",
    "    fc = Dense(1024, activation=\"elu\")(pool_2_flat)\n",
    "    fc_drop = Dropout(dropout_prob)(fc)\n",
    "    \n",
    "    lstm_in = Reshape([10, 1024])(fc_drop)\n",
    "    lstm_1 = LSTM(units=1024, return_sequences=True, unit_forget_bias=True, dropout=dropout_prob)(lstm_in)\n",
    "    rnn_output = LSTM(units=1024, return_sequences=False, unit_forget_bias=True)(lstm_1)\n",
    "    \n",
    "    shape_rnn_out = rnn_output.get_shape().as_list()\n",
    "    fc_out = Dense(shape_rnn_out[1], activation=\"elu\")(rnn_output)\n",
    "    fc_drop = Dropout(dropout_prob)(fc_out)\n",
    "    y_ = Dense(n_labels)(fc_drop)\n",
    "    y_posi = Softmax()(y_)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = y_posi)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = model(input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3], X_train.shape[4]))\n",
    "opt = Adam(lr=learning_rate)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10, 10, 11, 1)]   0         \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 10, 10, 11, 32)    320       \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 10, 10, 11, 64)    18496     \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 10, 10, 11, 128)   73856     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 10, 14080)         0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10, 1024)          14418944  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 1024)          0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 10, 1024)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 10, 1024)          8392704   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1024)              8392704   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 5125      \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 32,351,749\n",
      "Trainable params: 32,351,749\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import backend as K\n",
    "\n",
    "# def recall_m(y_true, y_pred):\n",
    "#         true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#         possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "#         recall = true_positives / (possible_positives + K.epsilon())\n",
    "#         return recall\n",
    "\n",
    "# def precision_m(y_true, y_pred):\n",
    "#         true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#         predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "#         precision = true_positives / (predicted_positives + K.epsilon())\n",
    "#         return precision\n",
    "\n",
    "# def f1_m(y_true, y_pred):\n",
    "#     precision = precision_m(y_true, y_pred)\n",
    "#     recall = recall_m(y_true, y_pred)\n",
    "#     return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint_path = results_path + \"/model/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start date and time: 2019-12-12 20:08:02.102727\n",
      "Train on 474018 samples, validate on 150241 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/2\n",
      "474000/474018 [============================>.] - ETA: 0s - loss: 1.3202 - acc: 0.4484\n",
      "Epoch 00001: saving model to ./results/keras_2019_12_12_20_07/model/cp.ckpt\n",
      "474018/474018 [==============================] - 288s 608us/sample - loss: 1.3202 - acc: 0.4484 - val_loss: 1.9722 - val_acc: 0.3305\n",
      "Epoch 2/2\n",
      "474000/474018 [============================>.] - ETA: 0s - loss: 1.0186 - acc: 0.5928\n",
      "Epoch 00002: saving model to ./results/keras_2019_12_12_20_07/model/cp.ckpt\n",
      "474018/474018 [==============================] - 287s 606us/sample - loss: 1.0186 - acc: 0.5928 - val_loss: 2.2313 - val_acc: 0.2693\n",
      "Training end date and time: 2019-12-12 20:17:42.437378\n"
     ]
    }
   ],
   "source": [
    "print(\"Training start date and time:\", datetime.now())\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=300, shuffle=True, validation_data=(X_valid, y_valid), callbacks=[cp_callback])\n",
    "print(\"Training end date and time:\", datetime.now())\n",
    "model.save(results_path + \"/model/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_path + \"/train_hist\", \"wb\") as file:\n",
    "    pickle.dump(history.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start date and time: 2019-12-12 20:17:44.314626\n"
     ]
    }
   ],
   "source": [
    "print(\"Training start date and time:\", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
